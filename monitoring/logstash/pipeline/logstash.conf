input {
  # Docker container logs
  beats {
    port => 5044
  }
  
  # File-based logs
  file {
    path => "/usr/share/logstash/logs/nginx/*.log"
    start_position => "beginning"
    tags => ["nginx"]
  }
  
  file {
    path => "/usr/share/logstash/logs/backend/*.log"
    start_position => "beginning"
    tags => ["backend"]
    codec => json
  }
}

filter {
  # Parse Nginx access logs
  if "nginx" in [tags] {
    grok {
      match => { 
        "message" => "%{NGINXACCESS}"
      }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
    
    mutate {
      convert => { "response" => "integer" }
      convert => { "bytes" => "integer" }
      convert => { "responsetime" => "float" }
    }
  }
  
  # Parse backend application logs
  if "backend" in [tags] {
    if [level] {
      mutate {
        uppercase => [ "level" ]
      }
    }
    
    # Extract request ID for tracing
    if [request_id] {
      mutate {
        add_field => { "trace_id" => "%{request_id}" }
      }
    }
  }
  
  # Add common fields
  mutate {
    add_field => { 
      "environment" => "${ENVIRONMENT:production}"
      "service" => "pafar"
    }
  }
  
  # GeoIP enrichment for client IPs
  if [clientip] {
    geoip {
      source => "clientip"
      target => "geoip"
    }
  }
}

output {
  # Send to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logstash-pafar-%{+YYYY.MM.dd}"
    template_name => "pafar-logs"
    template => "/usr/share/logstash/templates/pafar-template.json"
    template_overwrite => true
  }
  
  # Debug output (remove in production)
  stdout {
    codec => rubydebug
  }
}